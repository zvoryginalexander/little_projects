# Автоэнкодеры
<img src="https://skymind.ai/images/wiki/deep_autoencoder.png"
     alt="autoencoder_image"
     width="550"
     style="float: left; margin-right: 10px;" />

## Суть
**Автоэнкодеры** - нейронные сети, устроенные по типу бутылочного горлышка, копирующие выходной вектор данных наиболее близким к входному вектору данных. Входной вектор восстанавливается с ошибками из-за потерь при сжатии данных при энкодинге, и для минимизации ошибки сеть вынуждена учиться отбирать наиболее важные признаки.

Автоэндокеры состоят из двух частей: 
1. **Энкодер** отвечает за сжатие изходного вектора в ветор признаков (*aka* Latent Representation, Latent Space)
2. **Декодер** восстанавливает исходные данные из вектора признаков


## Применение 
- Сглаживание шума: 

Автоэнкодеры можно обучить убирать шум из данных (Denoising Autoencoder). Это можно сделать, добавив шум ко входному изображению и научив автокодер его удалять. Таким образом, кодер будет извлекать наиболее важные функции и изучать более редкое представление данных.
- Снижение размерности:

Автоэнкодеры редко используются для сжатия данных используется редко, обычно для этого не используют нейронные сети, потому что они работают медленнее и хуже
- Генерация данных:

Для генерации данных используют VAE (вариационные автоэнкодеры), которые учатся отображать объекты в скрытое пространство в Latent Space и сэмплить из него.




Using data from [Kannada MNIST](https://www.kaggle.com/c/Kannada-MNIST)
